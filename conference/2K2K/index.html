<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>High-fidelity 3D Human Digitization from Single 2K Resolution Images | Project Page</title>
  <meta content="" name="Project page for 'High-fidelity 3D Human Digitization from Single 2K Resolution Images'">
  <meta content="" name="Sang-Hun Han, South Korea">
  <link rel="canonical" href="https://sanghunhan92.github.io/conference/2K2K/">

  <!-- Favicons -->
  <link href="/assets/img/favicon/favicon-publication.svg" rel="icon" type="image/svg+xml">
  <link href="/assets/img/favicon/favicon-publication-32px.png" rel="icon" type="image/png" sizes="32x32">
  <link href="/assets/img/favicon/favicon-publication-512px.png" rel="icon" type="image/png" sizes="512x512">
  <link href="/assets/img/favicon/favicon-publication.svg" rel="mask-icon" color="#000000">
  <link href="/assets/img/favicon/favicon-publication-180px.png" rel="apple-touch-icon" type="image/png" sizes="180x180">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="/asset/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Publication Files -->
  <link href="/asset/css/publication_style.css" rel="stylesheet">
</head>

<body>
  <main id="main">
    <section class="publication">
      <div class="container">
        <div class="publication-title">          
          <h5>CVPR 2023 Highlight</h5>
          <h2>High-fidelity 3D Human Digitization from Single 2K Resolution Images</h2>
          <h4>            
            Sang-Hun Han<sup>1</sup>,
            Min-Gyu Park<sup>2</sup>, 
            Ju Hong Yoon<sup>2</sup>, <br>
            Ju-Mi Kang<sup>2</sup>, 
            Young-Jae Park<sup>1</sup>, and 
            <a href="https://scholar.google.com/citations?user=Ei00xroAAAAJ" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom" data-bs-html="true" title="<b>Corresponding Author</b> <br> Go to Google Scholar">Hae-Gon Jeon<sup>1</sup></a>
          </h4>
          <h6>
            <sup>1</sup>Gwangju Institute of Science and Technology, 
            <sup>2</sup>Korea Electronics Technology Institute
          </h6>
          <div class="btn-group" role="group" aria-label="Top menu">
            <a class="btn btn-primary" target="_blank" href="https://arxiv.org/pdf/2303.15108.pdf">Paper</a>
            <a class="btn btn-outline-primary" target="_blank" href="https://github.com/SangHunHan92/2K2K">Code</a>            
            <a class="btn btn-outline-primary" target="_blank" href="https://sanghunhan92.github.io/conference/2K2K/">Video (Coming Soon)</a>
          </div>
        </div>
      </div>

      <div class="container">
        <div class="publication-detail">
          <h3>Abstract</h3>
          <p>High-quality 3D human body reconstruction requires high-fidelity and large-scale training data and appropriate network design that effectively exploits the high-resolution input images. To tackle these problems, we propose a simple yet effective 3D human digitization method called <b>2K2K</b>, which constructs a large-scale 2K human dataset and infers 3D human models from 2K resolution images. The proposed method separately recovers the global shape of a human and its details. The low-resolution depth network predicts the global structure from a low-resolution image, and the part-wise image-to-normal network predicts the details of the 3D human body structure. The high-resolution depth network merges the global 3D shape and the detailed structures to infer the high-resolution front and back side depth maps. Finally, an off-the-shelf mesh generator reconstructs the full 3D human model, which are available at https://github.com/SangHunHan92/2K2K. In addition, we also provide 2,050 3D human models, including texture maps, 3D joints, and SMPL parameters for research purposes. In experiments, we demonstrate competitive performance over the recent works on various datasets.</p>
          <br><br>

          <h3>Video</h3>
          <div class="row">
            <div class="col-md-6">
              <video width="" height="1024" autoplay loop src="/imgs/2K2K/hanni_zoom.mp4" type="video/mp4">
            </div>
            <div class="col-md-6">
              <video width="" height="1024" autoplay loop src="/imgs/2K2K/hun_resize3.mp4" type="video/mp4">
            </div>
          </div>
          <br><br>      

          <h3>Method</h3>
          <img src="/imgs/2K2K/teaser.svg" alt="Image" style='height: 100%; width: 100%; max-width: 1000px; object-fit: contain'>          
          <p>An overall framework of 2k2k method. The first phase predicts the low-resolution front/back view depth maps, and the high-resolution front/back view normal maps by merging each part-wise normal maps. In the second phase, the high-resolution depth network upsamples the low-resolution depth maps with the guidance of the high-resolution normal maps. Finally, the mesh generation via screened Poisson reconstructs the full 3D model. </p>          
          <br><br>

          <h3>Dataset</h3>
          <img src="/imgs/2K2K/dataset.jpg" alt="Image" style='height: 100%; width: 100%; max-width: 1000px; object-fit: contain'>          
          <p>The 2K2K dataset consists of 2,050 3D human models scanned from scan booths, including high-quality public human scan models. Our dataset contains subjects of various genders, ages, objects, poses, and cloths with high-resolution scans.</p>
          <br><br>

          <h3>Qualitative Results</h3>
          <img src="/imgs/2K2K/comparison_sup_merge.jpg" alt="Image" style='height: 100%; width: 100%; max-width: 1000px; object-fit: contain'>          
          <!-- <p>The 2K2K dataset consists of 2,050 3D human models scanned from scan booths, including high-quality public human scan models. Our dataset contains subjects of various genders, ages, objects, poses, and cloths with high-resolution scans.</p> -->
          <br><br><br>

          <h3>Internet Photo Results</h3>
          <img src="/imgs/2K2K/real_image.svg" alt="Image" style='height: 100%; width: 100%; max-width: 1000px; object-fit: contain'>          
          <br>
          <div style="text-align: center"> Single image 3D human reconstruction results in the wild. The images are downloaded from internet. </div>
          <br><br><br>

          <h3>Video Frame Results</h3>
          <img src="/imgs/2K2K/real_video.jpg" alt="Image" style='height: 100%; width: 100%; max-width: 1000px; object-fit: contain'>          
          <br>
          <div style="text-align: center"> The result of reconstructing a video taken by a Youtube, Samsung Galaxy mobile phone, and DSLR, respectively. </div>
          <br><br><br>

          <h3>BibTeX</h3>
          <pre>@inproceedings{han2023high,<br>  title={High-fidelity 3D Human Digitization from Single 2K Resolution Images},<br>  author={Han, Sang-Hun and Park, Min-Gyu and Yoon, Ju Hong and Kang, Ju-Mi and Park, Young-Jae and Jeon, Hae-Gon},<br>  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},<br>  year={2023}<br>}</pre>
        </div>
      </div>
    </section>
  </main>

  <!-- Vendor JS Files -->
  <script src="/asset/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Main JS File -->
  <script type="text/javascript">
    var tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]'))
    var tooltipList = tooltipTriggerList.map(function (tooltipTriggerEl) {
      return new bootstrap.Tooltip(tooltipTriggerEl)
    })
    var popoverTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle="popover"]'))
    var popoverList = popoverTriggerList.map(function (popoverTriggerEl) {
      return new bootstrap.Popover(popoverTriggerEl)
    })
  </script>

</body>
</html>
